{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "from scipy.special import logit, expit\n",
    "\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n",
      "(153164, 2)\n",
      "(5000, 8)\n",
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34513</th>\n",
       "      <td>5c2cb0ca34f4860c</td>\n",
       "      <td>\" Untold Story\"\" appeared, in November of 2009...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82707</th>\n",
       "      <td>dd349039e760b747</td>\n",
       "      <td>Electronic Music article disambiguation revers...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93996</th>\n",
       "      <td>fb5561a3908da18c</td>\n",
       "      <td>Please don't add indiscriminately fuill tables...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                       comment_text  \\\n",
       "34513  5c2cb0ca34f4860c  \" Untold Story\"\" appeared, in November of 2009...   \n",
       "82707  dd349039e760b747  Electronic Music article disambiguation revers...   \n",
       "93996  fb5561a3908da18c  Please don't add indiscriminately fuill tables...   \n",
       "\n",
       "       toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "34513      0             0        0       0       0              0  \n",
       "82707      0             0        0       0       0              0  \n",
       "93996      0             0        0       0       0              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "train = train.sample(5000)\n",
    "test = test.sample(1000)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "display(train.sample(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build word vectorizer\n",
    "\n",
    "word_vectorizer = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='word', token_pattern='\\w{1,}', \n",
    "                                  ngram_range=(1,1), max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectorizer.fit(all_text)\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buil char vectorizer\n",
    "char_vectorizer = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='char', ngram_range=(1, 5),\n",
    "    max_features=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vectorizer.fit(all_text)\n",
    "train_char_features = char_vectorizer.transform(train_text)\n",
    "test_char_features = char_vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merger word and char features\n",
    "\n",
    "train_features = hstack([train_char_features, train_word_features])\n",
    "test_features = hstack([test_char_features, test_word_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.9493670505075295\n",
      "CV score for class severe_toxic is 0.9734099567410658\n",
      "CV score for class obscene is 0.9620387331280331\n",
      "CV score for class threat is 0.9736508405133893\n",
      "CV score for class insult is 0.949419969852309\n",
      "CV score for class identity_hate is 0.903173731270408\n",
      "Total CV scor 0.9518433803354558\n"
     ]
    }
   ],
   "source": [
    "# losses = []\n",
    "predictions = {'id': test['id'], 'comment' : test['comment_text']}\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    classifier = LogisticRegression(max_iter= 200, solver ='sag')\n",
    "    \n",
    "#     cv_loss = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n",
    "#     losses.append(cv_loss)\n",
    "#     print('CV score for class {} is {}'.format(class_name, cv_loss))\n",
    "    \n",
    "    classifier.fit(train_features, train_target)\n",
    "    predictions[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "    \n",
    "# print('Total CV scor {}'.format(np.mean(losses)))\n",
    "\n",
    "submission = pd.DataFrame.from_dict(predictions)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>id</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>threat</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137164</th>\n",
       "      <td>the only bloody commie regime from Europe, strongly supported by Russia \\n\\n *</td>\n",
       "      <td>e53cafb5daffab9f</td>\n",
       "      <td>0.007739</td>\n",
       "      <td>0.021211</td>\n",
       "      <td>0.026910</td>\n",
       "      <td>0.007991</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.040529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43296</th>\n",
       "      <td>\" \\n\\n ==Speedy deletion of Weblogtr.com== \\n  A tag has been placed on Weblogtr.com, requesting that it be speedily deleted from Wikipedia. This has been done under section G4 of the criteria for...</td>\n",
       "      <td>47b53d786284ea86</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.004045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66962</th>\n",
       "      <td>\" \\n ::The postseason has been pretty pathetic. Go Rays! ''' ' \"</td>\n",
       "      <td>6f7f9b24882299ab</td>\n",
       "      <td>0.006754</td>\n",
       "      <td>0.108825</td>\n",
       "      <td>0.069433</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.199759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105148</th>\n",
       "      <td>I think my article on Chuck Parsons is close to ready for posting, and would appreciate a review.  It has references and is based on reading and interviews, in my own words.  I would like to post ...</td>\n",
       "      <td>af88a660f46bb293</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.071542</td>\n",
       "      <td>0.025790</td>\n",
       "      <td>0.005529</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>0.099327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106532</th>\n",
       "      <td>:It would have been better to leave it as a stub, since that encourages others to develop it. I have now restored the article and expanded a bit. I hope to make it a B-class article in the future,...</td>\n",
       "      <td>b1cb2880698df604</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.015758</td>\n",
       "      <td>0.018225</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>0.022075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                        comment  \\\n",
       "137164                                                                                                                           the only bloody commie regime from Europe, strongly supported by Russia \\n\\n *   \n",
       "43296   \" \\n\\n ==Speedy deletion of Weblogtr.com== \\n  A tag has been placed on Weblogtr.com, requesting that it be speedily deleted from Wikipedia. This has been done under section G4 of the criteria for...   \n",
       "66962                                                                                                                                          \" \\n ::The postseason has been pretty pathetic. Go Rays! ''' ' \"   \n",
       "105148  I think my article on Chuck Parsons is close to ready for posting, and would appreciate a review.  It has references and is based on reading and interviews, in my own words.  I would like to post ...   \n",
       "106532  :It would have been better to leave it as a stub, since that encourages others to develop it. I have now restored the article and expanded a bit. I hope to make it a B-class article in the future,...   \n",
       "\n",
       "                      id  identity_hate    insult   obscene  severe_toxic  \\\n",
       "137164  e53cafb5daffab9f       0.007739  0.021211  0.026910      0.007991   \n",
       "43296   47b53d786284ea86       0.002277  0.004374  0.002529      0.001855   \n",
       "66962   6f7f9b24882299ab       0.006754  0.108825  0.069433      0.010575   \n",
       "105148  af88a660f46bb293       0.008004  0.071542  0.025790      0.005529   \n",
       "106532  b1cb2880698df604       0.004189  0.015758  0.018225      0.004250   \n",
       "\n",
       "          threat     toxic  \n",
       "137164  0.002235  0.040529  \n",
       "43296   0.001337  0.004045  \n",
       "66962   0.002078  0.199759  \n",
       "105148  0.002568  0.099327  \n",
       "106532  0.002236  0.022075  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use random forest classsifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class toxic is 0.9233647965245019\n",
      "CV score for class severe_toxic is 0.9641951617195179\n",
      "CV score for class obscene is 0.9585807700161327\n",
      "CV score for class threat is 0.7026436107692037\n",
      "CV score for class insult is 0.9330290798572461\n",
      "CV score for class identity_hate is 0.866195947389301\n",
      "Total CV scor 0.9215891373573865\n"
     ]
    }
   ],
   "source": [
    "predictions = {'id': test['id'], 'comment' : test['comment_text']}\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    classifier = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "    \n",
    "    cv_loss = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n",
    "    losses.append(cv_loss)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_loss))\n",
    "    \n",
    "    classifier.fit(train_features, train_target)\n",
    "    predictions[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "    \n",
    "print('Total CV scor {}'.format(np.mean(losses)))\n",
    "\n",
    "submission = pd.DataFrame.from_dict(predictions)\n",
    "submission.to_csv('submission_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
