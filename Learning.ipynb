{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReScaling of Data for the Sklearn Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data must be prepraed before model building. The data prepration process mainly involved 3 steps\n",
    "    Data selection, data preprocessing and data transformation.\n",
    "    \n",
    "In this notebooks I am using two simple data transformation method to apply to your data in Python unsing Sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Rescaling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your preprossed data may contains attributes with mixture of scales for various quantities such as dollors, kilogram and sales valoume.\n",
    "\n",
    "Many ML algorithm expects or are more effectiveif data attributes are on the same scale. Two popular data scaling method are Data Normalization and standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization refers to rescaling real valued numeric attributes into the range 0 and 1.\n",
    "\n",
    "It is useful to scale the input attributes for a model that relies on the magnitude of values, such as distance measures used in k-nearest neighbors and in the preparation of coefficients in regression.\n",
    "\n",
    "The example below demonstrate data normalization of the Iris flowers dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "normalized_X = preprocessing.normalize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Standardization\n",
    "\n",
    "Standardization refers to shifting the distribution of each attribute to have a mean of zero and a standard deviation of one (unit variance).\n",
    "\n",
    "It is useful to standardize attributes for a model that relies on the distribution of attributes such as Gaussian processes.\n",
    "\n",
    "The example below demonstrate data standardization of the Iris flowers dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X= iris.data\n",
    "Y = iris.target\n",
    "\n",
    "Scaled_X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
